# ğŸµ Guia de Uso - MÃºltiplas InstÃ¢ncias

## ğŸ“‹ VisÃ£o Geral

O sistema suporta executar mÃºltiplas instÃ¢ncias em paralelo, cada uma com seu prÃ³prio backend, worker e Redis. Isso permite processar grandes volumes de arquivos simultaneamente.

## ğŸš€ InÃ­cio RÃ¡pido

### 1. Iniciar InstÃ¢ncias

```bash
# Iniciar 3 instÃ¢ncias
python orchestrator.py start --instances 3

# Ou iniciar uma instÃ¢ncia especÃ­fica
python orchestrator.py start --id 1
```

### 2. Verificar Status

```bash
# Ver status de todas as instÃ¢ncias
python orchestrator.py status

# Monitorar em tempo real
python helper_scripts.py monitor --follow
```

### 3. Distribuir Arquivos

```bash
# Distribuir arquivos HTML entre as instÃ¢ncias (estratÃ©gia balanceada)
python helper_scripts.py distribute pasta_com_htmls --strategy balanced

# Ou usar round-robin
python helper_scripts.py distribute pasta_com_htmls --strategy round-robin
```

### 4. Processar

Acesse cada instÃ¢ncia no navegador:
- InstÃ¢ncia 1: http://localhost:8000
- InstÃ¢ncia 2: http://localhost:8001
- InstÃ¢ncia 3: http://localhost:8002

Configure e inicie o processamento em cada uma.

### 5. Coletar Resultados

```bash
# Coletar todos os resultados em uma pasta
python helper_scripts.py collect --output resultados_finais
```

### 6. Parar InstÃ¢ncias

```bash
# Parar uma instÃ¢ncia especÃ­fica
python orchestrator.py stop --instance 1

# Parar todas
python orchestrator.py stop --all
```

## ğŸ“ Estrutura de DiretÃ³rios

```
projeto/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ instance_1/
â”‚   â”‚   â”œâ”€â”€ inputs/      # Arquivos HTML para processar
â”‚   â”‚   â”œâ”€â”€ outputs/     # Resultados JSON
â”‚   â”‚   â”œâ”€â”€ checkpoints/ # Estados do workflow
â”‚   â”‚   â””â”€â”€ logs/        # Logs da instÃ¢ncia
â”‚   â”œâ”€â”€ instance_2/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ instance_3/
â”‚       â””â”€â”€ ...
```

## ğŸ”§ Comandos Ãšteis

### Orchestrator

```bash
# Iniciar mÃºltiplas instÃ¢ncias
python orchestrator.py start --instances N

# Iniciar instÃ¢ncia especÃ­fica
python orchestrator.py start --id ID

# Parar instÃ¢ncia
python orchestrator.py stop --instance ID

# Parar todas
python orchestrator.py stop --all

# Ver status
python orchestrator.py status

# Reiniciar instÃ¢ncia
python orchestrator.py restart ID
```

### Helper Scripts

```bash
# Distribuir arquivos
python helper_scripts.py distribute DIR [--strategy balanced|round-robin]

# Coletar resultados
python helper_scripts.py collect [--output DIR]

# Monitorar instÃ¢ncias
python helper_scripts.py monitor [--follow]

# Limpar outputs
python helper_scripts.py clean [--instance ID]

# Validar estrutura
python helper_scripts.py validate
```

### Testes

```bash
# Testar sistema completo
python test_instances.py
```

## ğŸ“Š Exemplo de Workflow Completo

### CenÃ¡rio: Processar 90 arquivos HTML usando 3 instÃ¢ncias

```bash
# 1. Iniciar 3 instÃ¢ncias
python orchestrator.py start --instances 3

# 2. Verificar que estÃ£o rodando
python orchestrator.py status

# 3. Distribuir os 90 arquivos (30 por instÃ¢ncia)
python helper_scripts.py distribute meus_htmls --strategy balanced

# 4. Verificar distribuiÃ§Ã£o
python helper_scripts.py validate

# 5. Processar em cada instÃ¢ncia
# Abrir em 3 abas do navegador:
# - http://localhost:8000 (processar 30 arquivos)
# - http://localhost:8001 (processar 30 arquivos)
# - http://localhost:8002 (processar 30 arquivos)

# 6. Monitorar progresso
python helper_scripts.py monitor --follow

# 7. ApÃ³s conclusÃ£o, coletar resultados
python helper_scripts.py collect --output resultados_completos

# 8. Parar instÃ¢ncias
python orchestrator.py stop --all
```

## ğŸ³ Docker

Cada instÃ¢ncia usa containers Docker separados:

- `redis_instance_N`: Redis dedicado
- `backend_instance_N`: FastAPI backend
- `worker_instance_N`: Celery worker

### Ver logs Docker

```bash
# Logs de uma instÃ¢ncia especÃ­fica
docker compose -f docker-compose.instance_1.yml logs -f

# Logs de um serviÃ§o especÃ­fico
docker compose -f docker-compose.instance_1.yml logs -f worker
```

## âš ï¸ SoluÃ§Ã£o de Problemas

### Problema: DuplicaÃ§Ã£o de pastas

**Sintoma:** Pastas aparecem como `data/instance_1/instance_1/`

**SoluÃ§Ã£o:** 
1. Pare todas as instÃ¢ncias: `python orchestrator.py stop --all`
2. Remova arquivos de configuraÃ§Ã£o antigos: `rm .env.instance_* docker-compose.instance_*.yml`
3. Reinicie: `python orchestrator.py start --instances N`

### Problema: Arquivos nÃ£o encontrados

**Sintoma:** "Arquivo nÃ£o encontrado" ao processar

**SoluÃ§Ã£o:**
1. Verifique onde os arquivos foram colocados: `python helper_scripts.py validate`
2. Redistribua se necessÃ¡rio: `python helper_scripts.py distribute DIR`

### Problema: Porta em uso

**Sintoma:** "Porta X jÃ¡ estÃ¡ em uso"

**SoluÃ§Ã£o:**
1. Verifique processos: `docker ps`
2. Pare containers Ã³rfÃ£os: `docker stop $(docker ps -q)`
3. Reinicie instÃ¢ncias

## ğŸ“ˆ Monitoramento e MÃ©tricas

### Ver estatÃ­sticas em tempo real

```bash
# Monitor interativo
python helper_scripts.py monitor --follow
```

### Verificar saÃºde das APIs

```bash
# Para cada instÃ¢ncia
curl http://localhost:8000/health
curl http://localhost:8001/health
curl http://localhost:8002/health
```

## ğŸ’¡ Dicas

1. **Balanceamento de carga**: Use `--strategy balanced` para distribuir igualmente
2. **Processamento em lote**: Configure todas as instÃ¢ncias antes de iniciar
3. **Logs centralizados**: Cada instÃ¢ncia tem sua pasta de logs em `data/instance_N/logs/`
4. **Backup**: Os resultados ficam em `data/instance_N/outputs/` atÃ© serem coletados

## ğŸ” VerificaÃ§Ã£o Final

ApÃ³s processar, verifique:

```bash
# 1. Validar estrutura
python helper_scripts.py validate

# 2. Contar arquivos processados
find data -name "*.json" -type f | wc -l

# 3. Verificar se hÃ¡ erros nos logs
grep -r "ERROR" data/*/logs/

# 4. Coletar todos os resultados
python helper_scripts.py collect --output resultados_finais
```

## ğŸ“ ObservaÃ§Ãµes

- Cada instÃ¢ncia Ã© independente e tem seu prÃ³prio Redis
- Os arquivos de configuraÃ§Ã£o (.env.instance_N) sÃ£o gerados automaticamente
- Os dados sÃ£o preservados mesmo apÃ³s parar as instÃ¢ncias
- Use `clean` para limpar outputs antes de novo processamento

---

**VersÃ£o:** 1.0
**Ãšltima atualizaÃ§Ã£o:** Outubro 2025